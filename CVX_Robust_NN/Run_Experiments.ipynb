{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OpRxRt0aNn80BoT6VV1je6F3Iv_71IsJ","timestamp":1714336150427}],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyNa2V2oB/t7kdzL5JXL2CZX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KSQ_n4q6JQe9","executionInfo":{"status":"ok","timestamp":1714340725912,"user_tz":420,"elapsed":32092,"user":{"displayName":"Daniel Kuelbs","userId":"00355856873650556171"}},"outputId":"4975d478-2381-46f6-d180-544bc5663573"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# put folder name here\n","FOLDERNAME = 'CVX_Robust_NN/'\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from torch.utils.data import Dataset, DataLoader, RandomSampler\n","\n","import os\n","\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","from prepare_data import *\n","from models.mobilenetv2 import *\n","from models.vgg import *\n","from models.spliced import *\n","from fgsm import *\n","#from models.vit_small import *\n","from models.praresnet import *\n","from cvx_scripts.losses import *\n","from cvx_scripts.cvx_nn import *\n","from cvx_scripts.cvx_training import *"]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0fPQkUlJX8f","executionInfo":{"status":"ok","timestamp":1714340725913,"user_tz":420,"elapsed":18,"user":{"displayName":"Daniel Kuelbs","userId":"00355856873650556171"}},"outputId":"ebc8b8ec-3f8b-4482-e5e9-d355d4fb3aea"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"code","source":["# Load CIFAR-10 data\n","print('==> Preparing data..')\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = datasets.CIFAR10(\n","    root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(\n","    trainset, batch_size=128, shuffle=True)\n","\n","testset = datasets.CIFAR10(\n","    root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(\n","    testset, batch_size=100, shuffle=False)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer',\n","           'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","mean = torch.tensor([0.4914, 0.4822, 0.4465]).to(device)\n","std = torch.tensor([0.2023, 0.1994, 0.2010]).to(device)\n","\n","beta = 1e-2\n","batch_size = 128\n","rho, solver_type = 1e-2, \"adam\"\n","trunc_d = 512\n","\n","# test loader with batch size of one for fast gradient sign method\n","testloader_fgsm = torch.utils.data.DataLoader(\n","    testset, batch_size=1, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7b3KEvL2JaE2","executionInfo":{"status":"ok","timestamp":1714340735835,"user_tz":420,"elapsed":9924,"user":{"displayName":"Daniel Kuelbs","userId":"00355856873650556171"}},"outputId":"e47c8034-5165-4a6e-ae17-765732bee3dc"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["==> Preparing data..\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:06<00:00, 28298856.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["# load in pre-trained Pre-Activaiton ResNet-18 models trained via sharpness-aware minimization and standard training.\n","pr18_sam = PreActResNet18(10)\n","pr18_sam.load_state_dict(torch.load(sys.path[-1] + 'praresnet.pth', map_location=torch.device('cpu')))\n","pr18_sam.to(device)\n","\n","pr18 = PreActResNet18(10)\n","pr18.load_state_dict(torch.load(sys.path[-1] + 'praresnet_nonsam.pth', map_location=torch.device('cpu')))\n","pr18.to(device)\n","\n","# load in a pre-trained convex two-layer ReLU network\n","cvx = custom_cvx_layer(512, 500)\n","cvx.load_state_dict(torch.load(sys.path[-1] + 'praresnet_nonsam_500_inf_5.pth', map_location=torch.device('cpu')))\n","cvx.to(device)\n","uvec = torch.from_numpy(torch.load(sys.path[-1] + 'u_vec_praresnet_nonsam_500.pth')).to(device).float()\n","\n","spliced = Spliced(pr18, cvx, uvec)"],"metadata":{"id":"6br_D3a4JlM5","executionInfo":{"status":"ok","timestamp":1714340743361,"user_tz":420,"elapsed":7529,"user":{"displayName":"Daniel Kuelbs","userId":"00355856873650556171"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# run FGSM attacks of varying sizes on each of the three models and plot the results\n","attack_sizes = np.arange(9)\n","acc_dict = {'PreActResNet18-SAM': [], 'PreActResNet18-ST': [], 'PreActResNet18-ST-CVX': []}\n","for attack in attack_sizes:\n","  acc_dict['PreActResNet18-SAM'].append(eval_fgsm(pr18_sam, device, testloader_fgsm, attack/255, mean, std))\n","  acc_dict['PreActResNet18-ST'].append(eval_fgsm(pr18, device, testloader_fgsm, attack/255, mean, std))\n","  acc_dict['PreActResNet18-ST-CVX'].append(eval_fgsm(spliced, device, testloader_fgsm, attack/255, mean, std))\n","\n","plt.plot(attack_sizes, acc_dict['PreActResNet18-ST-CVX'], label='CVX', color='red')\n","plt.plot(attack_sizes, acc_dict['PreActResNet18-SAM'], label='SAM', color='blue')\n","plt.plot(attack_sizes, acc_dict['PreActResNet18-ST'], label='ST', color='green')\n","plt.xlabel(r'$\\epsilon$')\n","plt.ylabel(r'robust test accuracy')\n","plt.legend()\n","plt.savefig(sys.path[-1] + '/REPRODUCED_robust_relu_accs.png')"],"metadata":{"id":"GRVTgQLEa4be"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Make Accuracy Plots for varying robustness parameter choices\n"],"metadata":{"id":"wKiPOvisg65S"}},{"cell_type":"code","source":["trunc_d = 512\n","# data extraction\n","print('Extracting the data')\n","dummy_loader= torch.utils.data.DataLoader(\n","    trainset, batch_size=1000, shuffle=False,\n","    pin_memory=True, sampler=None)\n","i = 0\n","A = torch.zeros(0, trunc_d).to(device)\n","y_all = torch.zeros(0).to(device)\n","for img, y in dummy_loader:\n","    i += 1\n","    img, y = img.to(device), y.to(device)\n","    out = pr18.truncated_forward(img).detach()\n","    A = torch.vstack((A,out))\n","\n","    y_all = torch.cat((y_all, y))\n","    pass\n","Apatch=A.detach().clone()\n","A = A.view(A.shape[0], -1)\n","n,trunc_d=A.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WjcEac68ooA-","executionInfo":{"status":"ok","timestamp":1714340762401,"user_tz":420,"elapsed":19042,"user":{"displayName":"Daniel Kuelbs","userId":"00355856873650556171"}},"outputId":"d6cc1f21-0007-4529-d077-a95064ddba4c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting the data\n"]}]},{"cell_type":"code","source":["# train convex heads for varying values of the robustness parameter. plot the results\n","\n","epochs = [5]\n","epsilons = {np.inf: np.linspace(20,50,16)} #{np.inf: [7.5, 10, 12.5, 15]} # for {1: [.1, .15, .2], 2: [1, 2, 3], np.inf: [10, 20, 30, 40]}\n","learning_rates = [1e-6]\n","norm_orders =  [np.inf]#[1, 2, np.inf]\n","num_neurons = [500]\n","LBFGS_param = [10, 4]\n","best_models = {}\n","rob_acc = []\n","clean_acc = []\n","acc = []\n","for hidden_size in num_neurons:\n","\n","  hidden_size,sign_pattern_list, u_vector_list = generate_sign_patterns(A.cpu(), hidden_size, False)\n","  sign_patterns = np.array([sign_pattern_list[i].int().data.numpy() for i in range(hidden_size)])\n","  u_vectors = np.asarray(u_vector_list).reshape((hidden_size, A.shape[1])).T\n","  ds_train = PrepareData3D(X=A, y=y_all, z=sign_patterns.T)\n","  ds_train = DataLoader(ds_train, batch_size=batch_size)\n","\n","  best_model, best_acc = None, 0\n","  key = None\n","  best_acc = 0\n","\n","  for norm_order in norm_orders:\n","    for epoch in epochs:\n","      for eps in epsilons[norm_order]:\n","        for lr in learning_rates:\n","          print('training under the following hyperparameters:', hidden_size, norm_order, epoch, eps, lr)\n","          # train a robust convex NN\n","          results_cvx_conv1 = sgd_solver_cvxproblem(pr18, ds_train, testloader, epoch, hidden_size, beta,\n","                                  lr, batch_size, rho, u_vectors, solver_type, LBFGS_param, verbose=True,\n","                                                    n=n, d=trunc_d, device='cuda', robust=True, eps=eps, norm=norm_order)\n","\n","          # merge convex and base model:\n","          splice_vecs = torch.tensor(u_vectors)\n","          splice_vecs = splice_vecs.to(device)\n","          cur_spliced = Spliced(pr18, results_cvx_conv1[-1], splice_vecs)\n","          cur_spliced.robust = True\n","\n","          # record avg accuracy on test set under two different attack sizes of FGSM:\n","          print('evaluating...')\n","\n","          acc.append(results_cvx_conv1[3])\n","          rob_acc.append(eval_fgsm(cur_spliced, device, testloader_fgsm, 1/255, mean, std))\n","\n","plt.plot(epsilons[np.inf], rob_acc, label = r'CVX with parameter $r$', color='red')\n","plt.xlabel(r'$r$')\n","plt.ylabel(r'robust test accuracy for $\\epsilon=1$')\n","# 0.6132 is standard-trained robust accuracy at eps = 1/255\n","# 0.7321 is SAM-trained robust accuracy at eps = 1/255\n","plt.hlines(0.6132, 20, 50, color='green', linestyles='--', label='ST')\n","plt.hlines(0.7321, 20, 50, color='blue', linestyles='--', label='SAM')\n","plt.legend()\n","plt.savefig(sys.path[-1] + '/REPRODUCED_relu_robust_acc_vs_r.png')"],"metadata":{"id":"dPgFvolEg-T-"},"execution_count":null,"outputs":[]}]}