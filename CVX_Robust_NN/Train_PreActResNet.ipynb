{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1jm5YnV03T4fgFkihN6E0D--0iZv1uUeR","authorship_tag":"ABX9TyPfLW/LPGKHYOoH6JQPDusS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zaQGF8DLUbvh","executionInfo":{"status":"ok","timestamp":1710282868908,"user_tz":420,"elapsed":10738,"user":{"displayName":"Daniel Kuelbs","userId":"00355856873650556171"}},"outputId":"2d95cae0-204d-4088-9d85-f9d06ceae711"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","FOLDERNAME = 'CVX_Robust_NN/'\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","source":["Import dependencies"],"metadata":{"id":"N55sfuJjYzXW"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from torch.utils.data import Dataset, DataLoader, RandomSampler\n","\n","import os\n","\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","from prepare_data import *\n","from models.mobilenetv2 import *\n","from models.vgg import *\n","from models.praresnet import *\n","from cvx_scripts.losses import *\n","from cvx_scripts.cvx_nn import *\n","from cvx_scripts.cvx_training import *\n","from sam import *\n","from pgd import *"],"metadata":{"id":"okQroPZSVaVI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set device"],"metadata":{"id":"XaCEjwyIY0ui"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jy_t4Bl4U8qX","executionInfo":{"status":"ok","timestamp":1710282884185,"user_tz":420,"elapsed":11,"user":{"displayName":"Daniel Kuelbs","userId":"00355856873650556171"}},"outputId":"566cb915-02c1-470c-f080-e92095cecfad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"markdown","source":["Load the CIFAR-10 Dataset"],"metadata":{"id":"_c8EDyHZY-0k"}},{"cell_type":"code","source":["# Data\n","print('==> Preparing data..')\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = datasets.CIFAR10(\n","    root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(\n","    trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = datasets.CIFAR10(\n","    root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(\n","    testset, batch_size=100, shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer',\n","           'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8Ii2pcmZB-n","executionInfo":{"status":"ok","timestamp":1710282901943,"user_tz":420,"elapsed":17766,"user":{"displayName":"Daniel Kuelbs","userId":"00355856873650556171"}},"outputId":"844532be-02c2-4caa-8cf7-5a9f6671adf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==> Preparing data..\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:13<00:00, 12606128.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"markdown","source":["Set parameters, intialize model and optimizer."],"metadata":{"id":"hzRJqHWPaA66"}},{"cell_type":"code","source":["lr = 0.1 #1e-4 # 0.1\n","best_acc = 0\n","start_epoch = 0"],"metadata":{"id":"HeBYaaNqbL0o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net = PreActResNet18(10)\n","\n","net = net.to(device)\n","criterion = nn.CrossEntropyLoss()\n","base_opt = torch.optim.SGD\n","optimizer = SAM(net.parameters(), base_opt,lr=lr, momentum=0.9, weight_decay=5e-4, rho=0.6)"],"metadata":{"id":"2b2qeFpzZ_q7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training\n","def train(epoch, sam=False):\n","    print('\\nEpoch: %d' % epoch)\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        outputs = net(inputs)\n","        loss = criterion(outputs, targets)\n","\n","        if sam:\n","          loss.backward()\n","          optimizer.first_step(zero_grad=True)\n","\n","          output_2 = net(inputs)\n","          criterion(output_2, targets).backward()\n","          optimizer.second_step(zero_grad=True)\n","        else:\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","    print(train_loss, 100.*correct / total)\n","\n","def test(epoch, best_acc):\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","    # Save checkpoint.\n","    acc = 100.*correct/total\n","    if acc > best_acc:\n","        best_acc = acc\n","    print(best_acc)"],"metadata":{"id":"Ure3DuB2b57p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def lr_schedule(epoch, total_epochs, initial_lr):\n","    if epoch < total_epochs * 0.75:\n","        return initial_lr\n","    elif epoch < total_epochs * 0.9:\n","        return initial_lr * 0.1\n","    else:\n","        return initial_lr * 0.01\n","\n","for epoch in range(start_epoch, start_epoch+100):\n","    lr = lr_schedule(epoch, 100, 0.1)\n","    optimizer.param_groups[0].update(lr=lr)\n","    train(epoch, sam = True)\n","    test(epoch, best_acc)\n","\n","torch.save(net.state_dict(), sys.path[-1] + 'praresnet.pth')"],"metadata":{"id":"79Ob-sXxcGiH"},"execution_count":null,"outputs":[]}]}